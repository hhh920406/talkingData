{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/randomstate/__init__.py:66: RandomStateDeprecationWarning: \n",
      "**End-of-life notification**\n",
      "\n",
      "This library was designed to bring alternative generators to the NumPy \n",
      "infrastructure. It as been successful in advancing the conversation \n",
      "for a future implementation of a new random number API in NumPy which \n",
      "will allow new algorithms and/or generators. The next step\n",
      "in this process is to separate the basic (or core RNG) from the \n",
      "functions that transform random bits into useful random numbers.\n",
      "This has been implemented in a successor project  **randomgen** \n",
      "available on GitHub\n",
      "\n",
      "https://github.com/bashtage/randomgen\n",
      "\n",
      "or PyPi\n",
      "\n",
      "https://pypi.org/project/randomstate/.\n",
      "\n",
      "randomgen has a slightly different API, so please see the randomgen documentation\n",
      "\n",
      "https://bashtage.github.io/randomgen.\n",
      "\n",
      "  warnings.warn(DEPRECATION_MESSAGE, RandomStateDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import wordbatch\n",
    "from wordbatch.extractors import WordHash\n",
    "from wordbatch.models import FM_FTRL\n",
    "from wordbatch.data_utils import *\n",
    "import threading\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_combinations = [\n",
    "    ['app'],\n",
    "    ['ip'],  # 3.03\n",
    "    ['channel'],\n",
    "    ['os'],\n",
    "    ['ip', 'device'],  # 9.88\n",
    "    ['day', 'hour', 'app'],  # 4.08\n",
    "    ['app', 'channel'],  # 2.8\n",
    "    ['ip', 'day', 'hour'],  # 0.52\n",
    "    ['os', 'device'],  # 0.44\n",
    "    ['ip', 'os', 'day', 'hour'],  # 0.41\n",
    "    ['ip', 'device', 'day', 'hour'],  # 0.31\n",
    "    ['ip', 'app', 'os']  # 0.21\n",
    "]\n",
    "\n",
    "countUniq_combinations = [\n",
    "    # [['app'],'ip'],\n",
    "    # [['app', 'device', 'os', 'channel'], 'ip'],\n",
    "    [['ip'], 'channel'],  # 0.9\n",
    "    [['ip'], 'app'],  # 1.3\n",
    "    [['ip'], 'os']  # 0.45\n",
    "]\n",
    "\n",
    "nextClick_combinations = [\n",
    "    ['ip', 'os'],\n",
    "    ['ip', 'app', 'device', 'os']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "\n",
    "import os, psutil\n",
    "\n",
    "\n",
    "def cpuStats():\n",
    "    pid = os.getpid()\n",
    "    py = psutil.Process(pid)\n",
    "    memoryUse = py.memory_info()[0] / 2. ** 30\n",
    "    print('memory GB:', memoryUse)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "mean_auc = 0\n",
    "\n",
    "\n",
    "def fit_batch(clf, X, y, w):  clf.partial_fit(X, y, sample_weight=w)\n",
    "\n",
    "\n",
    "def predict_batch(clf, X):  return clf.predict(X)\n",
    "\n",
    "\n",
    "def evaluate_batch(clf, X, y, rcount):\n",
    "    auc = roc_auc_score(y, predict_batch(clf, X))\n",
    "    global mean_auc\n",
    "    if mean_auc == 0:\n",
    "        mean_auc = auc\n",
    "    else:\n",
    "        mean_auc = 0.2 * (mean_auc * 4 + auc)\n",
    "    print(rcount, \"ROC AUC:\", auc, \"Running Mean:\", mean_auc)\n",
    "    return auc\n",
    "\n",
    "\n",
    "def count_agg(df, group_cols):\n",
    "    print('grouping features')\n",
    "    for i, cols in enumerate(group_cols):\n",
    "        col_name = \"_\".join(cols) + '_count'\n",
    "        count = df.groupby(cols).size().reset_index(name=col_name)\n",
    "        df = df.merge(count, on=cols, how='left')\n",
    "        del count\n",
    "        gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def count_uniq(df, group_uniq_cols):\n",
    "    print('unique features')\n",
    "    for i, cols in enumerate(group_uniq_cols):\n",
    "        group_cols, uniq_col = cols[0], cols[1]\n",
    "        col_name = \"_\".join(group_cols) + '_uniq_' + uniq_col + '_countUniq'\n",
    "        tmp = df.groupby(group_cols)[uniq_col].nunique().reset_index(name=col_name)\n",
    "        df = df.merge(tmp, on=group_cols, how='left')\n",
    "        del tmp\n",
    "        gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def next_click(df, group_cols):\n",
    "    print('next click features')\n",
    "    df['click_time'] = (df['click_time'].astype(np.int64) // 10 ** 9).astype(np.int32)\n",
    "    for i, cols in enumerate(group_cols):\n",
    "        col_name = \"_\".join(cols) + '_nextClick'\n",
    "        df[col_name] = (df.groupby(cols).click_time.shift(-1) - df.click_time).astype(np.float32)\n",
    "        gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def df2csr(wb, df, pick_hours=None):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    with timer(\"Adding counts\"):\n",
    "        df['click_time'] = pd.to_datetime(df['click_time'])\n",
    "        dt = df['click_time'].dt\n",
    "        df['day'] = dt.day.astype('uint8')\n",
    "        df['hour'] = dt.hour.astype('uint8')\n",
    "        del (dt)\n",
    "\n",
    "        df = count_agg(df, count_combinations)\n",
    "        df = count_uniq(df, countUniq_combinations)\n",
    "        df = next_click(df, nextClick_combinations)\n",
    "\n",
    "    with timer(\"Log-binning features\"):\n",
    "        for fea in ['app_count',\n",
    "                    'ip_count',\n",
    "                    'channel_count',\n",
    "                    'os_count',\n",
    "                    'ip_device_count',\n",
    "                    'day_hour_app_count',\n",
    "                    'app_channel_count',\n",
    "                    'ip_day_hour_count',\n",
    "                    'os_device_count',\n",
    "                    'ip_os_day_hour_count',\n",
    "                    'ip_device_day_hour_count',\n",
    "                    'ip_app_os_count',\n",
    "                    'ip_uniq_channel_countUniq',\n",
    "                    'ip_uniq_app_countUniq',\n",
    "                    'ip_uniq_os_countUniq',\n",
    "                    'ip_os_nextClick',\n",
    "                    'ip_app_device_os_nextClick'\n",
    "                    ]:\n",
    "            df[fea] = np.log2(1 + df[fea].values).astype(int)\n",
    "\n",
    "    with timer(\"Generating str_array\"):\n",
    "        str_array = (\"I\" + df['ip'].astype(str) \\\n",
    "                     + \" A\" + df['app'].astype(str) \\\n",
    "                     + \" D\" + df['device'].astype(str) \\\n",
    "                     + \" O\" + df['os'].astype(str) \\\n",
    "                     + \" C\" + df['channel'].astype(str) \\\n",
    "                     + \" WD\" + df['day'].astype(str) \\\n",
    "                     + \" H\" + df['hour'].astype(str) \\\n",
    "                     + \" AXC\" + df['app'].astype(str) + \"_\" + df['channel'].astype(str) \\\n",
    "                     + \" OXC\" + df['os'].astype(str) + \"_\" + df['channel'].astype(str) \\\n",
    "                     + \" AXD\" + df['app'].astype(str) + \"_\" + df['device'].astype(str) \\\n",
    "                     + \" IXA\" + df['ip'].astype(str) + \"_\" + df['app'].astype(str) \\\n",
    "                     + \" AXO\" + df['app'].astype(str) + \"_\" + df['os'].astype(str) \\\n",
    "                     + \"AC\" + df['app_count'].astype(str) \\\n",
    "                     + \"IC\" + df['ip_count'].astype(str) \\\n",
    "                     + \"CC\" + df['channel_count'].astype(str) \\\n",
    "                     + \"OC\" + df['os_count'].astype(str) \\\n",
    "                     + \"IDC\" + df['ip_device_count'].astype(str) \\\n",
    "                     + \"DHAC\" + df['day_hour_app_count'].astype(str) \\\n",
    "                     + \"ACC\" + df['app_channel_count'].astype(str) \\\n",
    "                     + \"IDHC\" + df['ip_day_hour_count'].astype(str) \\\n",
    "                     + \"ODC\" + df['os_device_count'].astype(str) \\\n",
    "                     + \"IODHC\" + df['ip_os_day_hour_count'].astype(str) \\\n",
    "                     + \"IDDHC\" + df['ip_device_day_hour_count'].astype(str) \\\n",
    "                     + \"IAOC\" + df['ip_app_os_count'].astype(str) \\\n",
    "                     + \"IUC\" + df['ip_uniq_channel_countUniq'].astype(str) \\\n",
    "                     + \"IUA\" + df['ip_uniq_app_countUniq'].astype(str) \\\n",
    "                     + \"IUO\" + df['ip_uniq_os_countUniq'].astype(str) \\\n",
    "                     + \"ION\" + df['ip_os_nextClick'].astype(str) \\\n",
    "                     + \"IADON\" + df['ip_app_device_os_nextClick'].astype(str) \n",
    "                     ).values\n",
    "    # cpuStats()\n",
    "    if 'is_attributed' in df.columns:\n",
    "        labels = df['is_attributed'].values\n",
    "        weights = np.multiply([1.0 if x == 1 else 0.2 for x in df['is_attributed'].values],\n",
    "                              df['hour'].apply(lambda x: 1.0 if x in pick_hours else 0.5))\n",
    "    else:\n",
    "        labels = []\n",
    "        weights = []\n",
    "    return str_array, labels, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ThreadWithReturnValue(threading.Thread):\n",
    "    def __init__(self, group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None):\n",
    "        threading.Thread.__init__(self, group, target, name, args, kwargs, daemon=daemon)\n",
    "        self._return = None\n",
    "\n",
    "    def run(self):\n",
    "        if self._target is not None:\n",
    "            self._return = self._target(*self._args, **self._kwargs)\n",
    "\n",
    "    def join(self):\n",
    "        threading.Thread.join(self)\n",
    "        return self._return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 5000000\n",
    "D = 2 ** 20\n",
    "\n",
    "wb = wordbatch.WordBatch(None, extractor=(WordHash, {\"ngram_range\": (1, 1), \"analyzer\": \"word\",\n",
    "                                                     \"lowercase\": False, \"n_features\": D,\n",
    "                                                     \"norm\": None, \"binary\": True})\n",
    "                         , minibatch_size=batchsize // 80, procs=8, freeze=True, timeout=1800, verbose=0)\n",
    "clf = FM_FTRL(alpha=0.05, beta=0.1, L1=0.0, L2=0.0, D=D, alpha_fm=0.02, L2_fm=0.0, init_fm=0.01, weight_fm=1.0,\n",
    "              D_fm=8, e_noise=0.0, iters=2, inv_link=\"sigmoid\", e_clip=1.0, threads=4, use_avx=1, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 5000000 227.62053513526917\n",
      "memory GB: 1.9478111267089844\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 10000000 525.7184975147247\n",
      "memory GB: 2.3234786987304688\n",
      "10000000 ROC AUC: 0.9745651774599268 Running Mean: 0.9745651774599268\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 41 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 148 s\n",
      "Training 15000000 851.9294579029083\n",
      "memory GB: 2.624431610107422\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 20000000 1145.4692740440369\n",
      "memory GB: 2.211658477783203\n",
      "20000000 ROC AUC: 0.9683387927007022 Running Mean: 0.9733199005080819\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 42 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 25000000 1466.6529309749603\n",
      "memory GB: 2.6913833618164062\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 41 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 30000000 1764.8575196266174\n",
      "memory GB: 2.9753570556640625\n",
      "30000000 ROC AUC: 0.9733478534062981 Running Mean: 0.9733254910877251\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 35000000 2089.1054067611694\n",
      "memory GB: 2.9623565673828125\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 146 s\n",
      "Training 40000000 2385.0382177829742\n",
      "memory GB: 2.8841781616210938\n",
      "40000000 ROC AUC: 0.9774640639463225 Running Mean: 0.9741532056594446\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 41 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 146 s\n",
      "Training 45000000 2704.936663866043\n",
      "memory GB: 2.7643775939941406\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 50000000 2998.2805643081665\n",
      "memory GB: 2.9196701049804688\n",
      "50000000 ROC AUC: 0.9801504367222452 Running Mean: 0.9753526518720048\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 39 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 149 s\n",
      "Training 55000000 3323.360859155655\n",
      "memory GB: 3.0685882568359375\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 39 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 149 s\n",
      "Training 60000000 3622.3480241298676\n",
      "memory GB: 2.3555679321289062\n",
      "60000000 ROC AUC: 0.9685419239799189 Running Mean: 0.9739905062935876\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 65000000 3944.0199427604675\n",
      "memory GB: 3.0107765197753906\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 70000000 4232.590351819992\n",
      "memory GB: 2.636463165283203\n",
      "70000000 ROC AUC: 0.9759715986873083 Running Mean: 0.9743867247723318\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 75000000 4557.927364110947\n",
      "memory GB: 2.794708251953125\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 41 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 80000000 4850.067337274551\n",
      "memory GB: 2.8362197875976562\n",
      "80000000 ROC AUC: 0.979075189084094 Running Mean: 0.9753244176346842\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 85000000 5168.086678981781\n",
      "memory GB: 2.3478317260742188\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 90000000 5461.925878763199\n",
      "memory GB: 2.7953529357910156\n",
      "90000000 ROC AUC: 0.9745685903117774 Running Mean: 0.975173252170103\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 41 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 95000000 5783.882947683334\n",
      "memory GB: 3.18951416015625\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 100000000 6080.251963376999\n",
      "memory GB: 3.5879440307617188\n",
      "100000000 ROC AUC: 0.9776985376051364 Running Mean: 0.9756783092571096\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 105000000 6396.508868455887\n",
      "memory GB: 3.0739974975585938\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 110000000 6689.3176164627075\n",
      "memory GB: 2.8143463134765625\n",
      "110000000 ROC AUC: 0.9797327962031683 Running Mean: 0.9764892066463213\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 39 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 147 s\n",
      "Training 115000000 7010.823716640472\n",
      "memory GB: 2.646251678466797\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 145 s\n",
      "Training 120000000 7303.225748062134\n",
      "memory GB: 2.391429901123047\n",
      "120000000 ROC AUC: 0.9710553820325588 Running Mean: 0.9754024417235689\n",
      "grouping features\n",
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 40 s\n",
      "[Log-binning features] done in 2 s\n",
      "[Generating str_array] done in 144 s\n",
      "Training 125000000 7623.8535215854645\n",
      "memory GB: 2.7701873779296875\n",
      "grouping features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py:1457: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  stride //= shape[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique features\n",
      "next click features\n",
      "[Adding counts] done in 1 s\n",
      "[Log-binning features] done in 0 s\n",
      "[Generating str_array] done in 0 s\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5575237b3eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/wordbatch/wordbatch.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, texts, extractor, cache_features, input_split, reset, update)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_split\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_output\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcache_features\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mwordbatch/extractors/extractors.pyx\u001b[0m in \u001b[0;36mwordbatch.extractors.extractors.WordHash.transform\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/wordbatch/wordbatch.py\u001b[0m in \u001b[0;36mparallelize_batches\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallelize_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/wordbatch/batcher.py\u001b[0m in \u001b[0;36mparallelize_batches\u001b[0;34m(self, task, data, args, method, timeout, rdd_col, input_split, merge_output, minibatch_size, procs)\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mattempt\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmerge_output\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/wordbatch/batcher.py\u001b[0m in \u001b[0;36mmerge_batches\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mssp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dtypes = {\n",
    "    'ip': 'uint32',\n",
    "    'app': 'uint16',\n",
    "    'device': 'uint16',\n",
    "    'os': 'uint16',\n",
    "    'channel': 'uint16',\n",
    "    'is_attributed': 'uint8',\n",
    "}\n",
    "\n",
    "p = None\n",
    "rcount = 0\n",
    "\n",
    "for df_c in pd.read_csv('data/train.csv',\n",
    "                        engine='c', chunksize=batchsize,\n",
    "                        skiprows=range(1, 9308569), sep=\",\", dtype=dtypes):\n",
    "\n",
    "    rcount += batchsize\n",
    "    if rcount == 130000000:\n",
    "        df_c['click_time'] = pd.to_datetime(df_c['click_time'])\n",
    "        df_c['day'] = df_c['click_time'].dt.day.astype('uint8')\n",
    "        df_c = df_c[df_c['day'] == 8]\n",
    "    str_array, labels, weights = df2csr(wb, df_c, pick_hours={4, 5, 10, 13, 14})\n",
    "    del (df_c)\n",
    "    if p != None:\n",
    "        p.join()\n",
    "        del (X)\n",
    "    gc.collect()\n",
    "    X = wb.transform(str_array)\n",
    "    del (str_array)\n",
    "    if rcount % (2 * batchsize) == 0:\n",
    "        if p != None:  p.join()\n",
    "        p = threading.Thread(target=evaluate_batch, args=(clf, X, labels, rcount))\n",
    "        p.start()\n",
    "    print(\"Training\", rcount, time.time() - start_time)\n",
    "    cpuStats()\n",
    "    if p != None:  p.join()\n",
    "    p = threading.Thread(target=fit_batch, args=(clf, X, labels, weights))\n",
    "    p.start()\n",
    "    if rcount == 130000000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if p != None:\n",
    "    p.join()\n",
    "\n",
    "del (X)\n",
    "p = None\n",
    "click_ids = []\n",
    "test_preds = []\n",
    "rcount = 0\n",
    "for df_c in pd.read_csv('data/test.csv', engine='c', chunksize=batchsize,\n",
    "                        sep=\",\", dtype=dtypes):\n",
    "    rcount += batchsize\n",
    "    if rcount % (10 * batchsize) == 0:\n",
    "        print(rcount)\n",
    "    str_array, labels, weights = df2csr(wb, df_c)\n",
    "    click_ids += df_c['click_id'].tolist()\n",
    "    del (df_c)\n",
    "    if p != None:\n",
    "        test_preds += list(p.join())\n",
    "        del (X)\n",
    "    gc.collect()\n",
    "    X = wb.transform(str_array)\n",
    "    del (str_array)\n",
    "    p = ThreadWithReturnValue(target=predict_batch, args=(clf, X))\n",
    "    p.start()\n",
    "if p != None:  test_preds += list(p.join())\n",
    "\n",
    "df_sub = pd.DataFrame({\"click_id\": click_ids, 'is_attributed': test_preds})\n",
    "df_sub.to_csv(\"wordbatch_fm_ftrl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
